library(caret)
library(dplyr)
pml.training <- read.csv("pml-training.csv")
pml.testing <- read.csv("pml-testing.csv")
##remove row numbers
training <- pml.training[,-1]
testing <- pml.testing[,-1]
##remove timestamp and window data
excluded_cols <- c("raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training %>%
select(-any_of(excluded_cols))
testing <- testing %>%
select(-any_of(excluded_cols))
##change divide by zero and blanks to NA
training[training=="#DIV/0!"] <- NA
testing[testing=="#DIV/0!"] <- NA
training[training==""] <- NA
testing[testing==""] <- NA
##There are a lot of NA's in the data set. Let's remove columns with more than
##80% NA's
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove))
testing <- testing %>%
select(-any_of(remove))
View(training)
##remove row numbers
training <- pml.training[,-1]
testing <- pml.testing[,-1]
##We want to determine if the sensor data can be used predict whether an excercise
##was done correctly, therefore, we wll remove the  user, timestamp and window data
excluded_cols <- c("user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training %>%
select(-any_of(excluded_cols))
testing <- testing %>%
select(-any_of(excluded_cols))
##change divide by zero and blanks to NA
training[training=="#DIV/0!"] <- NA
testing[testing=="#DIV/0!"] <- NA
training[training==""] <- NA
testing[testing==""] <- NA
##There are a lot of NA's in the data set. Let's remove columns with more than
##80% NA's
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove))
testing <- testing %>%
select(-any_of(remove))
summary(training)
##Convert classe to factor
training <- training %>%
mutate(classe = factor(classe))
##Check for near zero variance
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv ##No TRUE values
##let's look at correlations of predictors:
descrCor <-  cor(training)
##let's look at correlations of predictors:
descrCor <-  cor(training[,-c("classe")])
##let's look at correlations of predictors:
descrCor <-  cor(training[,-"classe"])
##let's look at correlations of predictors:
descrCor <-  cor(training[,-53])
descrCor
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
highCorr
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .9)
highCorr
highlyCorDescr <- findCorrelation(descrCor, cutoff = .9)
highlyCorDescr
train_ucor <- training[,-highlyCorDescr]
train_ucor <- training[,-highlyCorDescr]
View(train_ucor)
dim(train_ucor)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .85)
train_ucor <- training[,-highlyCorDescr]
dim(train_ucor)
highlyCorDescr
comboInfo <- findLinearCombos(train_ucor)
ctrl = rfeControl(functions = rfFuncs, # "rfFuncs" are built-in to caret
method = "repeatedcv", repeats = 10,
saveDetails = TRUE)
# Set a sequence of feature-space sizes to search over:
sizes = seq(sqrt(ncol(train_ucor))*.5, ncol(train_ucor), by = 5)
rfeResults = rfe(x = select(train_ucor, -classe), y = train_ucor$classe,
sizes = sizes,
rfeControl = ctrl)
str(train_ucor)
# Set a sequence of feature-space sizes to search over:
sizes = c(1:20, 25, 30, 35, 40, 44)
# Use caret's rfe function to fit RF models to these different feature spaces
rfeResults = rfe(x = select(train_ucor, -classe), y = train_ucor$classe,
sizes = sizes,
rfeControl = ctrl)
##check if training data is balanced
table training$classe
##check if training data is balanced
table(training$classe)
summary(training$yaw_belt)
summary(training$total_accel_belt)
table(training$total_accel_belt)
table(training$total_accel_arm)
table(training$total_accel_dumbbell)
trctrl <- trainControl(method="repeatedcv", number=10, repeats=3)
library(caret)
library(dplyr)
trctrl <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1122)
mod_svm <- train(classe~., data=train_ucor, method="svmLinear",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
mod_svm
library(arrow)
source("~/.active-rstudio-document")
View(f)
View(testing)
library(caret)
library(dplyr)
pml.training <- read.csv("pml-training.csv")
pml.testing <- read.csv("pml-testing.csv")
##remove row numbers
training <- pml.training[,-1]
testing <- pml.testing[,-1]
excluded_cols <- c("user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training %>%
select(-any_of(excluded_cols))
test_final <- testing %>%
select(-any_of(excluded_cols))
training[training=="#DIV/0!"] <- NA
test_final[test_final=="#DIV/0!"] <- NA
training[training==""] <- NA
test_final[test_final==""] <- NA
inTrain = createDataPartition(training$classe, p = 3/4, list=FALSE)
training = training[inTrain,]
testing = training[-inTrain,]
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove))
training <- training %>%
mutate(classe = factor(classe))
testing <- testing %>%
mutate(classe = factor(classe))
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv ##No TRUE values
descrCor <-  cor(training[,-53])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .85)
train_ucor <- training[,-highlyCorDescr]
table(training$classe)
trctrl <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1122)
mod_svm <- train(classe~., data=train_ucor, method="svmLinear",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
mod_svm
pred <- predict(mod_svm, newdata = testing)
pred
confusionMatrix(pred, testing$classe)
set.seed(1122)
linear_svm <- train(classe~., data=train_ucor, method="svmRadial",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
pred <- predict(linear_svm, newdata = testing)
confusionMatrix(pred, testing$classe)
set.seed(1122)
linear_svm <- train(classe~., data=train_ucor, method="svmLinear",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
linear_svm
pred1 <- predict(linear_svm, newdata = testing)
confusionMatrix(pred1, testing$classe)
##try non-linear SVM
set.seed(1122)
non_linear_svm <- train(classe~., data=training, method="svmRadial",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
pred2 <- predict(non_linear_svm, newdata = testing)
non_linear_svm
confusionMatrix(pred2, testing$classe)
##their are 8 predictors that meet this threshhold, let's try removing them
training <- training[,-highlyCorDescr]
##check if training data is balanced
table(training$classe)
table(testing$classe)
set.seed(1122)
non_linear_svm <- train(classe~., data=training, method="svmRadial",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
non_linear_svm
confusionMatrix(pred2, testing$classe)
library(caret)
library(dplyr)
View(test_final)
dim(test_final)
dim(pml.training)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
table(training$classe)
pml.training <- read.csv("pml-training.csv")
##remove row numbers
training <- pml.training[,-1]
str(training)
pml.training <- read.csv("pml-training.csv")
##remove row numbers
training <- pml.training[,-1]
str(training, list.len=10)
head(training, list=10)
head(training)
str(training)
library(caret)
library(dplyr)
pml.training <- read.csv("pml-training.csv")
##remove row numbers
training <- pml.training[,-1]
str(training, list.len=10)
excluded_cols <- c("user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
training <- training %>%
select(-any_of(excluded_cols))
##change divide by zero and blanks to NA
training[training=="#DIV/0!"] <- NA
training[training==""] <- NA
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove)) %>%
mutate(classe = factor(classe))
set.seed(1121)
inTrain = createDataPartition(training$classe, p = 3/4, list=FALSE)
training = training[inTrain,]
testing = training[-inTrain,]
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
descrCor <-  cor(training[,-53])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .85)
##there are 8 predictors that meet this threshold
training <- training[,-highlyCorDescr]
trctrl <- trainControl(method="repeatedcv", number=10, repeats=3)
linear_svm <- train(classe~., data=training, method="svmLinear",
trControl=trctrl, preProcess=c("center", "scale"),
tuneLength=10)
linear_svm
library(caret)
library(dplyr)
test_new <- read.csv("pml-testing.csv")
pred2 <- predict(non_linear_svm, newdata = test_new)
pred2
pml.training <- read.csv("pml-training.csv")
##remove row numbers
training <- pml.training[,-1]
excluded_cols <- c("user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
training <- training %>%
select(-any_of(excluded_cols))
training[training=="#DIV/0!"] <- NA
test_final[test_final=="#DIV/0!"] <- NA
set.seed(1121)
inTrain = createDataPartition(training$classe, p = 3/4, list=FALSE)
training = training[inTrain,]
testing = training[-inTrain,]
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove))
training <- training %>%
mutate(classe = factor(classe))
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv ##No TRUE values
dim(training)
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove))
dim(training)
training[training==""] <- NA
pml.training <- read.csv("pml-training.csv")
##remove row numbers
training <- pml.training[,-1]
excluded_cols <- c("user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
training <- training %>%
select(-any_of(excluded_cols))
##change divide by zero and blanks to NA
training[training=="#DIV/0!"] <- NA
training[training==""] <- NA
set.seed(1121)
inTrain = createDataPartition(training$classe, p = 3/4, list=FALSE)
training = training[inTrain,]
testing = training[-inTrain,]
remove <- names(training[,which(colMeans(is.na(training))>=.8)])
training <- training %>%
select(-any_of(remove))
training <- training %>%
mutate(classe = factor(classe))
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv ##No TRUE values
dim(training)
##look at correlations of predictors:
descrCor <-  cor(training[,-53])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .85)
##there are 8 predictors that meet this threshhold, try removing them
training <- training[,-highlyCorDescr]
##The testing data set provided does not have the outcome variable, therefore,
##for training and testing the model, we will break the original training dataset
##into a training and testing data sets.
set.seed(1121)
non_linear_svm <- train(classe~., data=training, method="svmRadial",
trControl=trctrl, preProcess=c("center", "scale"),
tuneGrid = expand.grid(C=2^(0:6)))
